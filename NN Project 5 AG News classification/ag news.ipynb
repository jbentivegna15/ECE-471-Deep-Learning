{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 4\n",
    "epochs = 2\n",
    "\n",
    "# load the data and split between train and test sets   \n",
    "train_df = pd.read_csv(\"ag_news_csv\\\\train.csv\", names=['label', 'title', 'description'])\n",
    "test_df = pd.read_csv(\"ag_news_csv\\\\train.csv\", names=['label', 'title', 'description'])\n",
    "print (\"retrieved data\")\n",
    "\n",
    "# subtract 1 from labels to make them 0-3\n",
    "train_df['label'] -= 1\n",
    "test_df['label'] -= 1\n",
    "\n",
    "# split data into x_train and y_train\n",
    "y_train = train_df['label']\n",
    "x_train = train_df['title'].map(str) + train_df['description'].map(str)\n",
    "y_test = test_df['label']\n",
    "x_test = test_df['title'].map(str) + test_df['description'].map(str)\n",
    "\n",
    "# spit train into train/val\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=10000, shuffle=True)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'val samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# find max length\n",
    "max_len = int(x_train.str.len().quantile(.95))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# tokenize data\n",
    "print (\"beginning to process data\")\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(x_train)\n",
    "encoded_train = t.texts_to_sequences(x_train)\n",
    "encoded_val = t.texts_to_sequences(x_val)\n",
    "encoded_test = t.texts_to_sequences(x_test)\n",
    "\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_len, padding='post')\n",
    "padded_val = pad_sequences(encoded_val, maxlen=max_len, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_len, padding='post')\n",
    "vocab = len(t.word_counts)\n",
    "print (\"finished processing data\")\n",
    "\n",
    "# constants\n",
    "l2weight = 0.0001\n",
    "\n",
    "# full model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab + 1, 8, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# build the graph\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(padded_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(padded_val, y_val))\n",
    "\n",
    "# score the model on the test set\n",
    "score = model.evaluate(padded_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
